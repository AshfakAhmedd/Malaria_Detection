{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbL3dHCsb6UT"
   },
   "source": [
    "# **Malaria Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50polMk6tjuY"
   },
   "source": [
    "##<b>Problem Definition</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCiPVBNbA0Wh"
   },
   "source": [
    "**The context:** Why is this problem important to solve?<br>\n",
    "Malaria is a global health issue that affects millions of people, particularly in regions with limited access to healthcare resources. Early and accurate detection of malaria is crucial for effective treatment and prevention of complications. However, traditional laboratory diagnosis methods for malaria are time-consuming, require specialized expertise, and may suffer from inter-observer variability. By developing an automated system for malaria detection using computer vision and deep learning techniques, we can significantly improve the speed, accuracy, and accessibility of diagnosis. This can lead to earlier detection, prompt treatment, and ultimately save lives.\n",
    "\n",
    "\n",
    "**The objectives:** What is the intended goal?<br>\n",
    "The goal of this project is to build a computer vision model using deep learning algorithms that can accurately identify and classify red blood cells as parasitized (infected with the Plasmodium parasite) or uninfected (free of the parasite). The model should provide a reliable and efficient tool for malaria detection, enabling early diagnosis and timely intervention.\n",
    "\n",
    "**The key questions:** What are the key questions that need to be answered?<br>\n",
    "\n",
    "1.   How can we leverage machine learning and artificial intelligence techniques to automate malaria detection?\n",
    "2.   What are the key features or patterns in the images of red blood cells that can distinguish between infected and uninfected cells?\n",
    "3.   Which deep learning algorithms and computer vision techniques are most suitable for this task?\n",
    "4.   How can we evaluate the performance of the developed model in terms of accuracy, precision, recall, and other relevant metrics?\n",
    "\n",
    "\n",
    "**The problem formulation:** What is it that we are trying to solve using data science?\n",
    "Using data science, we aim to develop an efficient computer vision model that can accurately detect malaria by analyzing images of red blood cells. The model will be trained to differentiate between infected (parasitized) and uninfected red blood cells, based on visual patterns and features present in the images. The goal is to build a robust and reliable system that can automate the detection process, reducing the reliance on manual inspection and improving diagnostic accuracy. By leveraging machine learning and artificial intelligence techniques, we can enable early and accurate malaria diagnosis, particularly in resource-constrained areas where access to skilled healthcare professionals may be limited.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exx2XXQ8nxRu"
   },
   "source": [
    "## <b>Data Description </b>\n",
    "\n",
    "There are a total of 24,958 train and 2,600 test images (colored) that we have taken from microscopic images. These images are of the following categories:<br>\n",
    "\n",
    "\n",
    "**Parasitized:** The parasitized cells contain the Plasmodium parasite which causes malaria<br>\n",
    "**Uninfected:** The uninfected cells are free of the Plasmodium parasites<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kqr8Q0PZ8zYI"
   },
   "source": [
    "## <b>Start of the Screening </b>\n",
    "\n",
    "Follow the general steps below to achieve the objective of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HDM89XHyCxrA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (23.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/2.1 MB 991.0 kB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.1/2.1 MB 1.3 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.2/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 0.2/2.1 MB 1.3 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 0.4/2.1 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.5/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.9/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 1.1/2.1 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.5/2.1 MB 3.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.7/2.1 MB 3.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.0/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.1/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.1/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 3.2 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HvHxBJ2H9zJc"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#import tensorflow as tf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#from tensorflow.keras import models , layers\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#image_size = (IMAGE_SIZE,IMAGE_SIZE)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#)\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras import models , layers\n",
    "\n",
    "#dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#\"cell_images\",\n",
    "#    shuffle=True,\n",
    "    #image_size = (IMAGE_SIZE,IMAGE_SIZE)\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC8-yLUUCcWh"
   },
   "source": [
    "### <b>Loading libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JOPQhfog90Id"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCqJk2XpCnJi"
   },
   "source": [
    "### <b>Load and reformat the data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XfYOt4m5Irf0"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "'''\n",
    "zip_ref1 = zipfile.ZipFile(\"/content/drive/MyDrive/test.zip\", 'r')\n",
    "zip_ref1.extractall(\"/content/drive/MyDrive/test_unzipped\")\n",
    "zip_ref1.close()\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/train.zip\", 'r')\n",
    "zip_ref.extractall(\"/content/drive/MyDrive/train_unzipped\")\n",
    "zip_ref.close()\n",
    "'''\n",
    "train_data_dir = 'E:\\\\Process\\\\cell_images\\\\train'\n",
    "test_data_dir = 'E:\\\\Process\\\\cell_images\\\\test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_rxFT9iH7pR"
   },
   "source": [
    "###<b> Check the shape of train and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GPl6Zj9mI1Xl"
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'E:\\\\Process\\\\cell_images\\\\train\\\\parasitized'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m train_images \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(train_data_dir)\n\u001b[0;32m      6\u001b[0m train_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_data_dir, train_images[\u001b[38;5;241m0\u001b[39m])  \n\u001b[1;32m----> 7\u001b[0m train_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_image_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m train_image_shape \u001b[38;5;241m=\u001b[39m train_image\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Image Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_image_shape)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'E:\\\\Process\\\\cell_images\\\\train\\\\parasitized'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Train data\n",
    "train_images = os.listdir(train_data_dir)\n",
    "train_image_path = os.path.join(train_data_dir, train_images[0])  \n",
    "train_image = Image.open(train_image_path)\n",
    "train_image_shape = train_image.size\n",
    "print(\"Train Image Shape:\", train_image_shape)\n",
    "\n",
    "# Test data\n",
    "test_images = os.listdir(test_data_dir)\n",
    "test_image_path = os.path.join(test_data_dir, test_images[0]) \n",
    "test_image = Image.open(test_image_path)\n",
    "test_image_shape = test_image.size\n",
    "print(\"Test Image Shape:\", test_image_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3AiiutGIEoy"
   },
   "source": [
    "###<b> Check the shape of train and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYJP2xGdJGtm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Train labels\n",
    "train_labels = os.listdir(train_data_dir)\n",
    "train_labels_shape = len(train_labels)\n",
    "print(\"Train Labels Shape:\", train_labels_shape)\n",
    "\n",
    "# Test labels\n",
    "test_labels = os.listdir(test_data_dir)\n",
    "test_labels_shape = len(test_labels)\n",
    "print(\"Test Labels Shape:\", test_labels_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFUMkif7IjlO"
   },
   "source": [
    "### <b>Check the minimum and maximum range of pixel values for train and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZercRxU4JHt3"
   },
   "outputs": [],
   "source": [
    "# Train images\n",
    "train_min_value = np.min(train_generator[0][0])\n",
    "train_max_value = np.max(train_generator[0][0])\n",
    "print(\"Train Image Pixel Range: {} - {}\".format(train_min_value, train_max_value))\n",
    "\n",
    "# Test images\n",
    "test_min_value = np.min(test_generator[0][0])\n",
    "test_max_value = np.max(test_generator[0][0])\n",
    "print(\"Test Image Pixel Range: {} - {}\".format(test_min_value, test_max_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywUFcLSCPIqz"
   },
   "source": [
    "###<b> Count the number of values in both uninfected and parasitized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcov18TYJsji"
   },
   "outputs": [],
   "source": [
    "# Counting values in uninfected class\n",
    "uninfected_count = np.sum(train_generator.classes == 0)\n",
    "print(\"Count of Uninfected Class:\", uninfected_count)\n",
    "\n",
    "# Counting values in parasitized class\n",
    "parasitized_count = np.sum(train_generator.classes == 1)\n",
    "print(\"Count of Parasitized Class:\", parasitized_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U71xb2XJe0t"
   },
   "source": [
    "###<b>Normalize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8masIGt9Jv7I"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NG4meNZBKZ5r"
   },
   "source": [
    "###<b> Plot to check if the data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_nuqkSfKNiU"
   },
   "outputs": [],
   "source": [
    "# Get the class labels and their corresponding count\n",
    "class_labels = train_generator.class_indices\n",
    "class_count = train_generator.classes.sum(axis=0)\n",
    "\n",
    "# Plotting the class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(class_labels.keys(), class_count)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16-Er2edMzsD"
   },
   "source": [
    "### <b>Data Exploration</b>\n",
    "Visualize the images from the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvRn7eDBKluv"
   },
   "outputs": [],
   "source": [
    "# Visualize images from train data\n",
    "images, labels = next(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ay4oo5HrTDha"
   },
   "source": [
    "###<b> Visualize the images with subplot(6, 6) and figsize = (12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR6d3b25KshO"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plotting images\n",
    "fig, axes = plt.subplots(6, 6, figsize=(12, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(36):\n",
    "    axes[i].imshow(images[i])\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifjZ2G0YN20r"
   },
   "source": [
    "###<b> Plotting the mean images for parasitized and uninfected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0Ny7AWlKvSa"
   },
   "outputs": [],
   "source": [
    "# Plotting mean images for parasitized and uninfected classes\n",
    "mean_parasitized_image = np.mean(images[labels == 1], axis=0)\n",
    "mean_uninfected_image = np.mean(images[labels == 0], axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(mean_parasitized_image)\n",
    "plt.title(\"Mean Parasitized Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mean_uninfected_image)\n",
    "plt.title(\"Mean Uninfected Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzBagGEzHMHB"
   },
   "source": [
    "### <b>Converting RGB to HSV of Images using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJFCdE77H1Sg"
   },
   "source": [
    "###<b> Converting the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vqQCGB1K-Dy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9a7cFllH794"
   },
   "source": [
    "###<b> Converting the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfebKiRIK-9s"
   },
   "outputs": [],
   "source": [
    "# Converting test data\n",
    "test_hsv_images = []\n",
    "for image in test_generator[0][0]:\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    test_hsv_images.append(hsv_image)\n",
    "\n",
    "test_hsv_images = np.array(test_hsv_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7x9uDxuJur7"
   },
   "source": [
    "###<b> Processing Images using Gaussian Blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgkB_-J2KhBQ"
   },
   "source": [
    "\n",
    "###<b> Gaussian Blurring on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkolUZQgLWiD"
   },
   "outputs": [],
   "source": [
    "train_blurred_images = []\n",
    "for image in train_generator[0][0]:\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    train_blurred_images.append(blurred_image)\n",
    "\n",
    "train_blurred_images = np.array(train_blurred_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTsJkRtCKlYZ"
   },
   "source": [
    "###<b> Gaussian Blurring on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vgj_S4PjLXca"
   },
   "outputs": [],
   "source": [
    "test_blurred_images = []\n",
    "for image in test_generator[0][0]:\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    test_blurred_images.append(blurred_image)\n",
    "\n",
    "test_blurred_images = np.array(test_blurred_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4Vso75QRcej"
   },
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4_ZzqDp8T5w"
   },
   "source": [
    "### **Base Model**\n",
    "\n",
    "**Note:** Build 3-5 models with  CNN architectures. Use custom or pretrained models of your choice. Start with a base model and continue from there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTMSr0Xw6x3b"
   },
   "source": [
    "###<b> Importing the required libraries for building and training our base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxX-x8wpMwSM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtayck2-Pm3G"
   },
   "source": [
    "####<B>One Hot Encoding the train and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4u_4OkbBM2RT"
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding the train and test labels\n",
    "train_labels_encoded = tf.keras.utils.to_categorical(train_generator.classes)\n",
    "test_labels_encoded = tf.keras.utils.to_categorical(test_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmwb4h0h64Km"
   },
   "source": [
    "###<b> Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7vtF13vM6J6"
   },
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Sh0OGP268Qm"
   },
   "source": [
    "###<b> Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDbAZG3VM_Fu"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Dt8lFvz6_K6"
   },
   "source": [
    "<b> Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaNUYVjLNBS0"
   },
   "outputs": [],
   "source": [
    "# Using Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint('base_model.h5', save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91af114l7DCt"
   },
   "source": [
    "<b> Fit and train our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EkBg4lt_NCVz"
   },
   "outputs": [],
   "source": [
    "# Fit and train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn7bDXku7Ib8"
   },
   "source": [
    "###<b> Evaluating the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzWqs0hjNUgQ"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSoNNG_T7PkT"
   },
   "source": [
    "<b> Plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOaMXihoNZ12"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Predict the classes for test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get the true classes for test data\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "class_names = ['Uninfected', 'Parasitized']\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWq4jyPL7f5a"
   },
   "source": [
    "<b>Plotting the train and validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDWqq5YgNlxH"
   },
   "outputs": [],
   "source": [
    "# Plot the train and validation curves\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.title('Train/Validation Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tJeklwR77rs"
   },
   "source": [
    "###<b> Model 1\n",
    "####<b> Try to improve the performance of our model by tuning hyperparameters or building a different model using other techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DT99NdnzZW3n"
   },
   "source": [
    "###<b> Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7tHSloUOecc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Building the Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6cTCOAVZZpI"
   },
   "source": [
    "###<b> Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EsNWKixOg3o"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PSskadUZhUt"
   },
   "source": [
    "<b> Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8GdtQsuOmMC"
   },
   "outputs": [],
   "source": [
    "# Using Callbacks\n",
    "early_stop = EarlyStopping(patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYLgQK9DZkoc"
   },
   "source": [
    "<b>Fit and Train the model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CoTbzkkKOp8m"
   },
   "outputs": [],
   "source": [
    "# Fit and Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHABkGRzZwyt"
   },
   "source": [
    "###<b> Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5OAsWGWPWN6"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCJEZ6cqZywk"
   },
   "source": [
    "<b> Plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pf13GFzyPaVi"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict classes for test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# Get true classes\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt=\"d\", cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roDugWeKaVDW"
   },
   "source": [
    "<b> Plotting the train and the validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZfkuPY2PbFg"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYVJZ0Psi0D0"
   },
   "source": [
    "###<b> Model 2\n",
    "####<b> Try to improve the performance of our model by tuning hyperparameters or building a different model using other techniques such as Augmentation, Batch Normalization, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqOnCq3FZ6JG"
   },
   "source": [
    "###<b> Use image data generator if augmentation is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpNgSUGuQcWH"
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "341Ilg5McowX"
   },
   "source": [
    "####<B>Visualizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dy3VUEZrQhJJ"
   },
   "outputs": [],
   "source": [
    "# Visualizing images\n",
    "class_names = train_generator.class_indices\n",
    "num_classes = len(class_names)\n",
    "\n",
    "sample_images, sample_labels = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(class_names[int(sample_labels[i])])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrpS4Azamjs4"
   },
   "source": [
    "###<b>Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lo0MPKMJQj9x"
   },
   "outputs": [],
   "source": [
    "# Building the Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-HrtTMJnEPl"
   },
   "source": [
    "<b>Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPmFUOTHQrM7"
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEeOIRrCnMBh"
   },
   "source": [
    "<b> Fit and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blZ5x9X-Qr_m"
   },
   "outputs": [],
   "source": [
    "# Fit and train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EFWVEUKoM1U"
   },
   "source": [
    "###<B>Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOhQygYKQu4G"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8twGIoxWnrCb"
   },
   "source": [
    "<b>Plot the train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-d208SDnQv1x"
   },
   "outputs": [],
   "source": [
    "# Plotting the train and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_VDQxXwoe6u"
   },
   "source": [
    "<B>Plotting the classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vq7DapgHQ_Eo"
   },
   "outputs": [],
   "source": [
    "# Plotting the classification report and confusion matrix\n",
    "test_predictions = model.predict(test_generator)\n",
    "test_pred_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "test_true_labels = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "classification_report = classification_report(test_true_labels, test_pred_labels, target_names=class_labels)\n",
    "confusion_mat = confusion_matrix(test_true_labels, test_pred_labels)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ra-GUCjbLHGg"
   },
   "source": [
    "### **Model 3: Use a Pre-trained model (VGG16) or other**\n",
    "- Import VGG16 or another pre-trained model upto any layer you choose\n",
    "- Add Fully Connected Layers on top of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIyarCI_R68C"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top classification layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze the weights of the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add your own fully connected layers on top of the pre-trained base model\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mhoug92KFWPa"
   },
   "source": [
    "###<b>Compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBPzjtxcFLQt"
   },
   "source": [
    "<b> using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awFoAXp7R88F"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_ZeobGmFIOF"
   },
   "source": [
    "<b>Fit and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXv91T6PSBxe"
   },
   "outputs": [],
   "source": [
    "# Fit and train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0WI9dvDFBaR"
   },
   "source": [
    "<b>Plot the train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0y7ylq6FSDx4"
   },
   "outputs": [],
   "source": [
    "# Plotting the train and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mb3jUduI0BNs"
   },
   "source": [
    "###**Observations and insights: _____**\n",
    "\n",
    "*   What can be observed from the validation and train curves?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykl7xLODEoix"
   },
   "source": [
    "###<b> Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5844m1BSVJB"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_lr-dUHE77F"
   },
   "source": [
    "<b>Plotting the classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmwhKXFJSXfK"
   },
   "outputs": [],
   "source": [
    "# Plotting the classification report and confusion matrix\n",
    "test_predictions = model.predict(test_generator)\n",
    "test_pred_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "test_true_labels = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "classification_report = classification_report(test_true_labels, test_pred_labels, target_names=class_labels)\n",
    "confusion_mat = confusion_matrix(test_true_labels, test_pred_labels)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Smzi8y5AEYIi"
   },
   "source": [
    "####<b> Observations and Conclusions drawn from the final model: _____\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yo6IpgOZ1n-g"
   },
   "source": [
    "**Improvements that can be done:**<br>\n",
    "\n",
    "\n",
    "*  **Can the model performance be improved using other pre-trained models or different CNN architecture?**\n",
    "\n",
    "\n",
    "*  **Use other filtering or other techniques to improve performance, if you would like**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJB6yf2EczFk"
   },
   "source": [
    "#### **Insights**\n",
    "\n",
    "####**Refined insights**:\n",
    "- What are the most meaningful insights from the data relevant to the problem?\n",
    "\n",
    "\n",
    "####**Comparison of various techniques and their relative performance**:\n",
    "- How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?\n",
    "\n",
    "\n",
    "####**Proposal for the final solution design**:\n",
    "- What model do you propose to be adopted? Why is this the best solution to adopt?\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
